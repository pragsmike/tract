Our task is to extract content from Substack HTML pages.
We will interchangably call these pages, articles, posts, or source pages.

The text of the articles is to be placed in Markdown-format files,
suitable for ingestion by LLMs.  Images will also be extracted
and stored alongside the text in a way that makes it obvious
which article they came from.  These images will also be given to LLMs.


* Access to the Substack Service

Some of the pages are free, available to everyone with no authentication.
Other pages are available only to subscribers.  We have subscriptions to those,
and have the authentication credentials.  These credentials will be stored
in a config.edn file that is excluded from version control, as is commonly
done for database and website credentials.

We must avoid being throttled or banned by the Substack service.
For that, we employ
   * throttling on our end, limiting requests to a small number per minute.
   * using different user-agent fields.
   * respecting robots.txt and robots headers in the responses from Substack.
   * optionally, using proxy servers to send the requests to Substack.

A Substack page is fetched by an HTTP GET request for a text/html document.

* Use cases
** Text ingested by LLM
   The LLM will ingest only the Markdown text extracted from the articles.
   It will know the name of the article, the author, the date of publication, and the text content.
   The text will contain links to external URLs, and to images encountered in the article,
   which will have been stored as described below.

** Images ingested by LLM
   The multimodal LLM will ingest one or more images.
   It will know the name of the article(s) that referenced the image, their author(s),
   and their date(s) of publication.
   It must be possible for the LLM to fetch, or at least ask for, the referring articles by name.

* Architecture

  We want a command-line program that can accept arguments, as implied below.

  We need two functions. One is given a substack author's name, and an optional
  date range. If the date range is omitted, it means the ten most recent
  articles by that author. This function could use Substack's Atom feed for that
  author. The output is a list of URLs of the articles by that author whose
  publication date lies within the date range.

  The second function is given a list of URLs, and produces a set of files
  that hold the content extracted from the articles found at those URLs.
  The content extracted is summarized here, with details specified in the next section.
  * the textual content of the body, as markdown, with images and links preserved.
    All the text is to be contained in that one file.
  * the images that are linked in the text, one per file, along with metadata
    that includes the image URL, the caption it appeared with in the article,
    and the URL of the article that referenced it.

* Output format

  For each article, we derive a unique, readable textual key that can serve as the prefix of the filenames.
  We will use this key to generate the names of files where we will store the extracted content.

  This key is a "slugified" version of the article title (shortened, with unsafe characters removed)
  prefixed by the date, as in 'YYYY-MM-DD_slugified-title'.

  For example, an article "My Thoughts on Skunks" published on Oct 27, 2023
  could have the key 2023-10-27_my-thoughts-on-skunks

** Body text

  The textual content of the article is stored in a Markdown-format file, suffix .md, whose name
  is prefixed by that key.  All the text in the article is to appear in that one file.

  The front matter of the file contains metadata in TOML format about the article from which it was extracted,
  including the title, author, article_key, publication_date, source_url.

  #+begin_src text
    ---
    title: "Skunk"
    author: "John Doe"
    article_key: "2023-10-27_skunk"
    publication_date: "2023-10-27"
    source_url: "https://johndoe.substack.com/p/skunk"
    ---

    The rest of the article content in Markdown...
  #+end_src

  If the source page contains section headings, they are to be preserved as headings in the Markdown file.

** Image references

  Image references in the article will appear as image references in the Markdown file.
  These are to be translated so they point at the image as stored alongside the Markdown file.

  The image itself will be fetched and stored in a file whose name is the file part of the URL
  it came from, under a directory whose name is the host part of that URL.
  If there is a query string, it should be removed.

  For example, supposed the article is named "Skunk".  The Markdown file containing its
  text will be named '2023-10-27_skunk.md'.  Suppose further that the article had an inline image reference

  <img src="https://example.com/sunset.jpg" alt="A beautiful sunset" title="Sunset Image">

  That would appear in the Markdown file as

  ![A beautiful sunset](example.com/sunset.jpg "Sunset Image")

  and that sunset.jpg file will have been stored in a directory 'example.com' alongside Skunk.md.


  It is possible, but not expected to be very common, that the same image will be referenced
  by multiple articles.  The image itself will be the same, stored in the same place,
  and need only be fetched once from its source URL.  However, the reference to it in each of the
  articles will in general be different.  The interesting info is the caption that appeared with
  the image, the title, the alt text, and the URL of the article that referenced it.

  Therefore for each image reference in an article, we will create a JSON file that holds
  those items alongside the image file.  That JSON file will be named using the article's textual key
  as described above, along with a small integer to make it unique in case the article refers
  to the image more than once.

  For example, the JSON file for the image above would look like this:
  #+begin_src json
    {
      "article_key": "2023-10-27_skunk",
      "source_article_url": "https://...",
      "image_path": "example.com/sunset.jpg",
      "image_source_url": "https://example.com/sunset.jpg",
      "alt": "A beautiful sunset",
      "title": "Sunset Image",
      "caption": "A beautiful sunset over the mountains."
    }
  #+end_src

*** Image Captions
   While some description of the image can be found in the IMG tag, finding the caption
   will require inspection of the surrounding HTML.
   Substack articles often have captions in separate HTML elements (e.g., a
   <figcaption> or a <div> with a specific class) that are siblings to the <img>'s
   parent container.

** Links

  Links to URLs in the article will appear as links in the Markdown file.


* Implementation

The implementation code is Clojure.  We use standard good coding practices,
preferring functional code over stateful code.

We use standard Clojure libraries.
Etaoin is a library that uses the WebDriver protocol to drive web browsers.
This reduces the possibility of being throttled or restricted by Substack,
as it shows fewer signs of being a bot.

For parsing the HTML content, we will use either Reaver or Enlive.
The latter is known to work.  We will have to evaluate them both.
For now, let's assume we'll use Enlive, but keep the possibility open.



